{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_F1RIdBzixN"
   },
   "source": [
    "# Quantitatively measuring exact image retrieval accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Yel4841zzKL"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vIYnI03-K8_s"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import hashlib\n",
    "import json\n",
    "from collections.abc import Iterable\n",
    "from dataclasses import dataclass, asdict\n",
    "from functools import lru_cache, partial\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from uuid import UUID\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import PIL\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "from IPython.display import HTML\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoImageProcessor, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Law1fj_xHjLW"
   },
   "source": [
    "## Utility functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJUfgf3jHlz5"
   },
   "source": [
    "### Class to transform images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yCFqppBQHh8n"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ImageAugmenter:\n",
    "    \"\"\"Class that takes care of augmenting an image.\n",
    "    \"\"\"\n",
    "    rotation: float\n",
    "    crop_left: float\n",
    "    crop_right: float\n",
    "    crop_top: float\n",
    "    crop_bottom: float\n",
    "    width_scale: float\n",
    "    height_scale: float\n",
    "\n",
    "    def __call__(self, image: PIL.Image.Image) -> PIL.Image.Image:\n",
    "        \"\"\"Augment the image, first rotating, then cropping before finally scaling.\n",
    "        \"\"\"\n",
    "        image = image.rotate(self.rotation, resample=PIL.Image.Resampling.BICUBIC, fillcolor=\"white\", expand=True)\n",
    "        width, height = image.size\n",
    "\n",
    "        left = round(self.crop_left*width)\n",
    "        right = round(width - self.crop_right*width)\n",
    "        upper = round(self.crop_top*height)\n",
    "        lower = round(height - self.crop_top*height)\n",
    "\n",
    "        new_width = round((right - left) * self.width_scale)\n",
    "        new_height = round((lower - upper) * self.height_scale)\n",
    "\n",
    "        return (\n",
    "            image\n",
    "            .crop((left, upper, right, lower))\n",
    "            .resize((new_width, new_height), resample=PIL.Image.Resampling.LANCZOS)\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def init_random(\n",
    "        cls,\n",
    "        min_rotation: float,\n",
    "        max_rotation: float,\n",
    "        max_crop_left: float,\n",
    "        max_crop_right: float,\n",
    "        max_crop_top: float,\n",
    "        max_crop_bottom: float,\n",
    "        min_scale_width: float,\n",
    "        max_scale_width: float,\n",
    "        min_scale_height: float,\n",
    "        max_scale_height: float,\n",
    "        rng: np.random.Generator,\n",
    "    ):\n",
    "        \"\"\"Create a random image augmenter.\n",
    "        \"\"\"\n",
    "        return cls(\n",
    "            rotation=rng.uniform(min_rotation, max_rotation),\n",
    "            crop_left=rng.uniform(0, max_crop_left),\n",
    "            crop_right=rng.uniform(0, max_crop_right),\n",
    "            crop_top=rng.uniform(0, max_crop_top),\n",
    "            crop_bottom=rng.uniform(0, max_crop_bottom),\n",
    "            width_scale=rng.uniform(min_scale_width, max_scale_width),\n",
    "            height_scale=rng.uniform(min_scale_height, max_scale_height),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exqt2509HqoU"
   },
   "source": [
    "## Functions that interact with the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wRoQk4dhJ-4D"
   },
   "outputs": [],
   "source": [
    "def get_url_uuid(url: str) -> str:\n",
    "    \"\"\"Convert the URL to the ID in the Qdrant database.\n",
    "    \"\"\"\n",
    "    sha_digest = hashlib.sha256(url.encode(\"utf-8\")).digest()\n",
    "    return UUID(bytes=sha_digest[:16]).urn.split(\":\")[-1]\n",
    "    \n",
    "\n",
    "def get_retrieval_test_urls() -> Iterable[str]:\n",
    "    \"\"\"Load the labelled dataset, extract the interesting classes and get image IDs.\n",
    "    \"\"\"\n",
    "    label_df = pd.read_json(\"../data/labelled_data.json\")\n",
    "    interesting_labels = [\"Illustration or photograph\", \"Map\", \"Mathematical chart\"]\n",
    "    url_mask = label_df[interesting_labels].any(axis=1)\n",
    "    urls = url_mask[url_mask].index\n",
    "    return urls\n",
    "\n",
    "@lru_cache\n",
    "def get_image_from_url(url: str, image_directory: Path) -> PIL.Image.Image:\n",
    "    \"\"\"Download the image given its ID.\n",
    "    \"\"\"\n",
    "    id_ = get_url_uuid(url)\n",
    "    filename = (image_directory / f\"{id_}.jpg\")\n",
    "    if filename.exists():\n",
    "        return PIL.Image.open(filename)\n",
    "\n",
    "    image_directory.mkdir(exist_ok=True, parents=True)\n",
    "    url = f\"https://api.nb.no/dhlab/image_search/id?image_id={id_}&limit=1&embedding_type=CLIP\"\n",
    "    response = requests.get(url).json()\n",
    "\n",
    "    image_url = response[0][\"payload\"][\"image_url\"]\n",
    "    image_resp = requests.get(image_url)\n",
    "    image_resp.raise_for_status()\n",
    "    jpg_contents = image_resp.content\n",
    "    filename.write_bytes(jpg_contents)\n",
    "    return PIL.Image.open(filename)\n",
    "\n",
    "@lru_cache\n",
    "def get_retrieval_score(\n",
    "    query_vector: tuple[float],\n",
    "    target_id: str,\n",
    "    embedding_type: str,\n",
    "    query_size: int = 10,\n",
    ") -> int:\n",
    "    \"\"\"Query the API and return the position of the target image in query (-1 if not there)\n",
    "    \"\"\"\n",
    "    result = requests.post(\n",
    "        f\"https://api.nb.no/dhlab/image_search/vector?&limit={query_size}\",\n",
    "        json={\n",
    "        \"vector\": list(query_vector),\n",
    "        \"embedding_type\": embedding_type\n",
    "        }\n",
    "    ).json()\n",
    "\n",
    "    for idx, element in enumerate(result):\n",
    "        if element[\"id\"] == target_id:\n",
    "            return idx\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def get_base64_image(image: PIL.Image.Image) -> str:\n",
    "    \"\"\"Base64-encode a PIL image to embed it in a dataframe.\n",
    "    \"\"\"\n",
    "    with BytesIO() as buffer:\n",
    "        image.save(buffer, 'jpeg')\n",
    "        return base64.b64encode(buffer.getvalue()).decode()\n",
    "\n",
    "def get_image_thumbnail(image: PIL.Image.Image, size: tuple[int, int] = (150, 150)) -> PIL.Image.Image:\n",
    "    \"\"\"Get a thumbnail from a PIL image.\n",
    "    \"\"\"\n",
    "    image_thumbnail = image.copy()\n",
    "    image_thumbnail.thumbnail(size)\n",
    "    return image_thumbnail\n",
    "\n",
    "def format_image(image_base64: str) -> str:\n",
    "    \"\"\"Add an img-tag for base64 encode JPEG-data.\n",
    "    \"\"\"\n",
    "    return f'<img src=\"data:image/jpeg;base64,{image_base64}\">'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwQfN6XlHyx4"
   },
   "source": [
    "### Functions to compute the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3tsMJojDHyXA"
   },
   "outputs": [],
   "source": [
    "def get_device() -> torch.device:\n",
    "    \"\"\"Get the torch device, use CUDA if available.\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "@lru_cache\n",
    "def load_model(model_name: str, device: torch.device) -> tuple[AutoImageProcessor, AutoModel]:\n",
    "    \"\"\"Get a pretrained huggingface processor and model. Note that these are cached!\n",
    "    \"\"\"\n",
    "    processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    return processor, model\n",
    "\n",
    "\n",
    "def calculate_embeddings(image: PIL.Image, model_name: str, multimodal: bool) -> tuple[float, ...]:\n",
    "    \"\"\"Compute embedding vectors for an image.\n",
    "    \"\"\"\n",
    "    device = get_device()\n",
    "    processor, model = load_model(model_name, device)\n",
    "\n",
    "    processed = processor(images=image, return_tensors=\"pt\")[\"pixel_values\"]\n",
    "    if multimodal:\n",
    "        embeddings = model.get_image_features(processed.to(device))\n",
    "    else:\n",
    "        model_out = model(processed.to(device), output_hidden_states=True)\n",
    "        embeddings = model_out.hidden_states[-1][:, 0, :]\n",
    "\n",
    "    return tuple(embeddings.detach().cpu().numpy().squeeze().tolist())\n",
    "\n",
    "\n",
    "def compute_embeddings(img: PIL.Image.Image) -> dict[str, tuple[float, ...]]:\n",
    "    \"\"\"Compute all relevant embedding vectors for an image.\n",
    "    \"\"\"\n",
    "    siglip_model = \"google/siglip-base-patch16-256-multilingual\"\n",
    "    clip_model = \"openai/clip-vit-base-patch32\"\n",
    "    vit_model = \"google/vit-base-patch16-224\"\n",
    "\n",
    "    return {\n",
    "        \"SigLIP\": calculate_embeddings(img, siglip_model, multimodal=True),\n",
    "        \"CLIP\": calculate_embeddings(img, clip_model, multimodal=True),\n",
    "        \"ViT\": calculate_embeddings(img, vit_model, multimodal=False),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KOkw0cn3SXK"
   },
   "source": [
    "## Run queries based on transformed images and measure accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XfO4gJOK0r9"
   },
   "source": [
    "### Image transformation parameters\n",
    "Set parameters for image transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "m6v3Q9TqOlft"
   },
   "outputs": [],
   "source": [
    "min_rotation = -10\n",
    "max_rotation = 10\n",
    "\n",
    "max_crop_left = 0.15\n",
    "max_crop_right = 0.15\n",
    "max_crop_top = 0.15\n",
    "max_crop_bottom = 0.15\n",
    "\n",
    "min_scale_width = 0.8\n",
    "max_scale_width = 1.2\n",
    "\n",
    "min_scale_height = 0.8\n",
    "max_scale_height = 1.2\n",
    "\n",
    "embedding_models = [\"ViT\", \"SigLIP\", \"CLIP\"]\n",
    "query_size = 100\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "image_directory = Path(\"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCfq-X3GU6Zm"
   },
   "source": [
    "### Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "3bbecd03fcf448b99b13cb0a1865d416",
      "c86b45e487ff4e439fcfca33dea7cdbb",
      "af14de0514af4f46a7b1c176ec000a0e",
      "94dc7c51fe684ec3b851454d036a9690",
      "d08da9437a584097a62ab5daeda6aede",
      "19bf683e234946eead97eeca8f6a9e42",
      "ca21ac34b6f24b3f9fc31a4eda6ca12b",
      "8d56c41821f647e0ac0f31d73414a7ae",
      "6ce1bf85dc394d45ae44f3154883aff5",
      "437951a076c94e8d882ef4fd2968e7db",
      "2993583b930f4d8ca93e1473a25b4554"
     ]
    },
    "id": "6BHTl4-NNRqn",
    "outputId": "22762dfb-d9ad-4f0f-e7f8-c5a5fe0adaea",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abec063befe54cc9ab5c7ecc0e4c4f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/684 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariero/book-image-labelling/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "urls = get_retrieval_test_urls()\n",
    "\n",
    "results = []\n",
    "\n",
    "for url in tqdm(urls):\n",
    "    try:\n",
    "        image = get_image_from_url(url, image_directory)\n",
    "    except requests.HTTPError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    augmenter = ImageAugmenter.init_random(\n",
    "        min_rotation=min_rotation,\n",
    "        max_rotation=max_rotation,\n",
    "        max_crop_left=max_crop_left,\n",
    "        max_crop_right=max_crop_right,\n",
    "        max_crop_top=max_crop_top,\n",
    "        max_crop_bottom=max_crop_bottom,\n",
    "        min_scale_width=min_scale_width,\n",
    "        max_scale_width=max_scale_width,\n",
    "        min_scale_height=min_scale_height,\n",
    "        max_scale_height=max_scale_height,\n",
    "        rng=rng,\n",
    "    )\n",
    "    augmented_image = augmenter(image)\n",
    "    embeddings = compute_embeddings(augmented_image)\n",
    "\n",
    "    retrieval_position = {\n",
    "        f\"{embedding_model} position\": get_retrieval_score(\n",
    "            tuple(embeddings[embedding_model]),\n",
    "            target_id=get_url_uuid(url),\n",
    "            embedding_type=embedding_model,\n",
    "            query_size=query_size,\n",
    "        )\n",
    "        for embedding_model in embedding_models\n",
    "    }\n",
    "    results.append(\n",
    "        {\n",
    "            \"url\": url,\n",
    "            \"image_thumbnail\": get_base64_image(get_image_thumbnail(image)),\n",
    "            \"augmented_image_thumbnail\": get_base64_image(get_image_thumbnail(augmented_image)),\n",
    "            **retrieval_position,\n",
    "            **asdict(augmenter),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "5sCO1Ka856QX",
    "outputId": "157a6b24-3b1d-4d16-c554-4a3f2781190b"
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(results)\n",
    "\n",
    "# Store CSV-file with results\n",
    "result_df[[\n",
    "    \"url\",\n",
    "    \"ViT position\",\n",
    "    \"SigLIP position\",\n",
    "    \"CLIP position\",\n",
    "    \"rotation\",\n",
    "    \"crop_left\",\n",
    "    \"crop_right\",\n",
    "    \"crop_top\",\n",
    "    \"crop_bottom\",\n",
    "    \"width_scale\",\n",
    "    \"height_scale\"\n",
    "]].to_csv(\"../data/image_retrieval_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NWCQG8DLUL_"
   },
   "source": [
    "## Evaluate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLBAr4q0LfnN"
   },
   "source": [
    "### Melt the results so it's easier to create accuracy-tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2pOwyGnOYHt5"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The following id_vars or value_vars are not present in the DataFrame: ['id']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tidy_results \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmelt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresult_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m position\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43membedding_models\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvar_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membedding_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mposition\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m tidy_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding_model\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tidy_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding_model\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x:x\u001b[38;5;241m.\u001b[39mremovesuffix(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m position\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/book-image-labelling/.venv/lib/python3.11/site-packages/pandas/core/reshape/melt.py:74\u001b[0m, in \u001b[0;36mmelt\u001b[0;34m(frame, id_vars, value_vars, var_name, value_name, col_level, ignore_index)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m     71\u001b[0m     missing_labels \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     72\u001b[0m         lab \u001b[38;5;28;01mfor\u001b[39;00m lab, not_found \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(labels, missing) \u001b[38;5;28;01mif\u001b[39;00m not_found\n\u001b[1;32m     73\u001b[0m     ]\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following id_vars or value_vars are not present in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe DataFrame: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_labels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m     )\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value_vars_was_not_none:\n\u001b[1;32m     79\u001b[0m     frame \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39miloc[:, algos\u001b[38;5;241m.\u001b[39munique(idx)]\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The following id_vars or value_vars are not present in the DataFrame: ['id']\""
     ]
    }
   ],
   "source": [
    "tidy_results = pd.melt(\n",
    "    result_df,\n",
    "    id_vars=[\"id\"],\n",
    "    value_vars=[f\"{model} position\" for model in embedding_models],\n",
    "    var_name=\"embedding_model\",\n",
    "    value_name=\"position\",\n",
    ")\n",
    "tidy_results[\"embedding_model\"] = tidy_results[\"embedding_model\"].apply(lambda x:x.removesuffix(\" position\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Pandas accuracy table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "jZ53iUd3bj9p",
    "outputId": "0bfd50a8-526c-43ed-b208-07517ba88f72"
   },
   "outputs": [],
   "source": [
    "accuracy_table = (\n",
    "    tidy_results\n",
    "    .eval(\n",
    "        \"\"\"\n",
    "        top_1 = position == 0\n",
    "        top_5 = -1 < position < 5\n",
    "        top_10 = -1 < position < 10\n",
    "        top_50 = -1 < position < 50\n",
    "        \"\"\"\n",
    "    )\n",
    "    .groupby(\"embedding_model\")\n",
    "    .sum()\n",
    "    [[\"top_1\", \"top_5\", \"top_10\", \"top_50\"]]\n",
    ")\n",
    "accuracy_table.columns.name = \"accuracy\"\n",
    "accuracy_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format dataframe as HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_count(cnt: int) -> str:\n",
    "    return f\"{cnt} ({cnt / len(result_df):.0%})\"\n",
    "\n",
    "latex_df = accuracy_table.copy()\n",
    "latex_df.index.name = \"Model\"\n",
    "latex_df.columns = latex_df.columns.map(lambda s: s.capitalize().replace(\"_\", \" \"))\n",
    "latex_df.columns.name = latex_df.columns.name.capitalize()\n",
    "\n",
    "HTML(\n",
    "    latex_df.to_html(\n",
    "        formatters={col: format_count for col in latex_df.columns},\n",
    "        escape=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create LaTeX table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def format_count(cnt: int, column: pd.Series) -> str:\n",
    "    data_str = f\"{cnt} \\\\ \\\\ ({100 * cnt / len(result_df):.0f} \\\\ \\\\%)\"\n",
    "    if cnt == column.max():\n",
    "        data_str = f\"\\\\mathbf{{{data_str}}}\"\n",
    "    return f\"\\\\({data_str}\\\\)\"\n",
    "        \n",
    "\n",
    "\n",
    "print(\n",
    "    latex_df.to_latex(\n",
    "        formatters={col: partial(format_count, column=latex_df[col]) for col in latex_df.columns},\n",
    "    ).replace(\"{lrrr}\", \"{@{}l@{\\hspace{2em}}r@{\\hspace{2em}}r@{\\hspace{2em}}r@{}}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJ4RsCs4LW-b"
   },
   "source": [
    "### Show tables of images its unable to find for the different embedding types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khDixLhk-EM-"
   },
   "source": [
    "#### SigLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GsGdSdUt6-gZ",
    "outputId": "b90f2ff9-618b-46bc-e4d6-911ee1db53a2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HTML(\n",
    "    result_df.query(\"`SigLIP position` == -1 or `SigLIP position` >= 50\").to_html(\n",
    "        formatters={\n",
    "            \"image_thumbnail\": format_image,\n",
    "            \"augmented_image_thumbnail\": format_image\n",
    "          },\n",
    "        escape=False\n",
    "      )\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MInSli28-H6n"
   },
   "source": [
    "#### CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8eroAALv6-U8",
    "outputId": "76a16fd3-95f9-4149-a490-2743355ad06c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(\n",
    "    result_df.query(\"`CLIP position` == -1 or `CLIP position` >= 50\").to_html(\n",
    "        formatters={\n",
    "            \"image_thumbnail\": format_image,\n",
    "            \"augmented_image_thumbnail\": format_image\n",
    "          },\n",
    "        escape=False\n",
    "      )\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jlav0LsH6-Eq"
   },
   "source": [
    "#### ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BbtbHNhx-NBy",
    "outputId": "88900fad-d789-446f-dac2-0c32e64f1109"
   },
   "outputs": [],
   "source": [
    "HTML(\n",
    "    result_df.query(\"`ViT position` == -1 or `ViT position` >= 50\").to_html(\n",
    "        formatters={\n",
    "            \"image_thumbnail\": format_image,\n",
    "            \"augmented_image_thumbnail\": format_image\n",
    "          },\n",
    "        escape=False\n",
    "      )\n",
    "  )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "mOnqEgztzy7b",
    "YbaurLtS-O4a"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "19bf683e234946eead97eeca8f6a9e42": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2993583b930f4d8ca93e1473a25b4554": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3bbecd03fcf448b99b13cb0a1865d416": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c86b45e487ff4e439fcfca33dea7cdbb",
       "IPY_MODEL_af14de0514af4f46a7b1c176ec000a0e",
       "IPY_MODEL_94dc7c51fe684ec3b851454d036a9690"
      ],
      "layout": "IPY_MODEL_d08da9437a584097a62ab5daeda6aede"
     }
    },
    "437951a076c94e8d882ef4fd2968e7db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ce1bf85dc394d45ae44f3154883aff5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8d56c41821f647e0ac0f31d73414a7ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94dc7c51fe684ec3b851454d036a9690": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_437951a076c94e8d882ef4fd2968e7db",
      "placeholder": "​",
      "style": "IPY_MODEL_2993583b930f4d8ca93e1473a25b4554",
      "value": " 103/1132 [05:23&lt;47:36,  2.78s/it]"
     }
    },
    "af14de0514af4f46a7b1c176ec000a0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d56c41821f647e0ac0f31d73414a7ae",
      "max": 1132,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6ce1bf85dc394d45ae44f3154883aff5",
      "value": 103
     }
    },
    "c86b45e487ff4e439fcfca33dea7cdbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19bf683e234946eead97eeca8f6a9e42",
      "placeholder": "​",
      "style": "IPY_MODEL_ca21ac34b6f24b3f9fc31a4eda6ca12b",
      "value": "  9%"
     }
    },
    "ca21ac34b6f24b3f9fc31a4eda6ca12b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d08da9437a584097a62ab5daeda6aede": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
